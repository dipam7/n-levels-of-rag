from datetime import datetime
from typing import List
from pydantic import field_validator
from lancedb.embeddings import get_registry
from lancedb.pydantic import LanceModel, Vector
from pydantic import BaseModel, Field

openai = get_registry().get("openai").create(name="text-embedding-3-large", dim=256)


class TextChunk(LanceModel):
    chunk_id: str
    doc_id: str
    text: str = openai.SourceField()
    vector: Vector(openai.ndims()) = openai.VectorField(default=None)
    post_title: str
    publish_date: datetime
    chunk_number: int
    source: str


class DocumentMetadata(LanceModel):
    date: str
    url: str
    title: str

    @field_validator("date")
    @classmethod
    def metadata_must_contain_a_valid_date_string(cls, v: str):
        try:
            datetime.strptime(v, "%Y-%m")
        except Exception as e:
            raise ValueError(
                f"Date format must be YYYY-MM (Eg. 2024-10). Unable to parse provided date of {v} "
            )
        return v


class Document(LanceModel):
    id: str
    content: str
    filename: str
    metadata: DocumentMetadata


class QuestionAnswerPair(BaseModel):
    """
    This model represents a pair of a question generated from a text chunk, its corresponding answer,
    and the chain of thought leading to the answer. The chain of thought provides insight into how the answer
    was derived from the question.
    """

    chain_of_thought: str = Field(
        ..., description="The reasoning process leading to the answer."
    )
    question: str = Field(
        ..., description="The generated question from the text chunk."
    )
    answer: str = Field(..., description="The answer to the generated question.")


class EvaluationDataItem(BaseModel):
    question: str
    answer: str
    chunk: str
    chunk_id: str


class KeywordExtractionResponse(BaseModel):
    """
    This is a response model which represents a list of potential short keywords that can be used to identify/find relevant sources of information related to the question.

    These should come both from the question itself AND generated by the llm
    """

    keywords: List[str] = Field(
        ...,
        title="Search Terms",
        description="A list of search terms, expanded acronyms, and synonyms, each item limited to a maximum of two words.",
        min_length=8,
        json_schema_extra={
            "examples": [
                "climate change",
                "global warming",
                "CO2 emissions",
            ]
        },
    )

    @field_validator("keywords")
    @classmethod
    def validate_search_terms(cls, v):
        invalid_terms = [term for term in v if len(term.split()) > 2]
        if invalid_terms:
            raise ValueError(
                f"The following keywords contain more than two words and are not allowed: {', '.join(invalid_terms)}. Consider breaking up these terms into smaller phrases. Existing list of words is {', '.join(v)}"
            )
        return v
